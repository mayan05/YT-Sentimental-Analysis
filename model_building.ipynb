{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Comment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2a9b0425-9270-4f64-b5aa-e1f7b661de1d",
       "rows": [
        [
         "0",
         "lets not forget that apple pay in 2014 required a brand new iphone in order to use it a significant portion of apples user base wasnt able to use it even if they wanted to as each successive iphone incorporated the technology and older iphones were replaced the number of people who could use the technology increased",
         "neutral"
        ],
        [
         "1",
         "here in nz 50 of retailers don’t even have contactless credit card machines like paywave which support apple pay they don’t like the high fees that come with these",
         "negative"
        ],
        [
         "2",
         "i will forever acknowledge this channel with the help of your lessons and ideas explanations now its quite helpful while youll just sit at your comfort and monitor your account growth",
         "positive"
        ],
        [
         "3",
         "whenever i go to a place that doesn’t take apple pay doesn’t happen too often it’s such a drag between ‘contactless covid’ habits and my getting the apple card i’ve gotten so used to apple pay that i get seriously annoyed when a store doesn’t take it it feels like a shock it’s crazy how quickly it took over my shopping routine i’ve officially been brainwashed by apple because now it feels so inconvenient to even carry a physical card in my pocket",
         "negative"
        ],
        [
         "4",
         "apple pay is so convenient secure and easy to use i used it while at the korean and japanese airports no need for physical credit cards",
         "positive"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets not forget that apple pay in 2014 require...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here in nz 50 of retailers don’t even have con...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i will forever acknowledge this channel with t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whenever i go to a place that doesn’t take app...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple pay is so convenient secure and easy to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment\n",
       "0  lets not forget that apple pay in 2014 require...   neutral\n",
       "1  here in nz 50 of retailers don’t even have con...  negative\n",
       "2  i will forever acknowledge this channel with t...  positive\n",
       "3  whenever i go to a place that doesn’t take app...  negative\n",
       "4  apple pay is so convenient secure and easy to ...  positive"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./YoutubeCommentsDataSet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comment      44\n",
       "Sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of missing values in the dataset: 0.2%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percent of missing values in the dataset: {round(44 / len(df), 3) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the duplication is less than 1% of the original dataset, we can just drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Comment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b3b32004-72b7-4807-8325-31eb6bcc6d88",
       "rows": [
        [
         "0",
         "lets not forget that apple pay in 2014 required a brand new iphone in order to use it a significant portion of apples user base wasnt able to use it even if they wanted to as each successive iphone incorporated the technology and older iphones were replaced the number of people who could use the technology increased",
         "neutral"
        ],
        [
         "1",
         "here in nz 50 of retailers don’t even have contactless credit card machines like paywave which support apple pay they don’t like the high fees that come with these",
         "negative"
        ],
        [
         "2",
         "i will forever acknowledge this channel with the help of your lessons and ideas explanations now its quite helpful while youll just sit at your comfort and monitor your account growth",
         "positive"
        ],
        [
         "3",
         "whenever i go to a place that doesn’t take apple pay doesn’t happen too often it’s such a drag between ‘contactless covid’ habits and my getting the apple card i’ve gotten so used to apple pay that i get seriously annoyed when a store doesn’t take it it feels like a shock it’s crazy how quickly it took over my shopping routine i’ve officially been brainwashed by apple because now it feels so inconvenient to even carry a physical card in my pocket",
         "negative"
        ],
        [
         "4",
         "apple pay is so convenient secure and easy to use i used it while at the korean and japanese airports no need for physical credit cards",
         "positive"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets not forget that apple pay in 2014 require...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here in nz 50 of retailers don’t even have con...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i will forever acknowledge this channel with t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whenever i go to a place that doesn’t take app...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple pay is so convenient secure and easy to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment\n",
       "0  lets not forget that apple pay in 2014 require...   neutral\n",
       "1  here in nz 50 of retailers don’t even have con...  negative\n",
       "2  i will forever acknowledge this channel with t...  positive\n",
       "3  whenever i go to a place that doesn’t take app...  negative\n",
       "4  apple pay is so convenient secure and easy to ...  positive"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    11054\n",
       "neutral      4503\n",
       "negative     2317\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Comment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "eb8515b5-9ae2-4265-a2aa-725d91eeebb0",
       "rows": [
        [
         "0",
         "lets not forget that apple pay in 2014 required a brand new iphone in order to use it a significant portion of apples user base wasnt able to use it even if they wanted to as each successive iphone incorporated the technology and older iphones were replaced the number of people who could use the technology increased",
         "0"
        ],
        [
         "1",
         "here in nz 50 of retailers don’t even have contactless credit card machines like paywave which support apple pay they don’t like the high fees that come with these",
         "-1"
        ],
        [
         "2",
         "i will forever acknowledge this channel with the help of your lessons and ideas explanations now its quite helpful while youll just sit at your comfort and monitor your account growth",
         "1"
        ],
        [
         "3",
         "whenever i go to a place that doesn’t take apple pay doesn’t happen too often it’s such a drag between ‘contactless covid’ habits and my getting the apple card i’ve gotten so used to apple pay that i get seriously annoyed when a store doesn’t take it it feels like a shock it’s crazy how quickly it took over my shopping routine i’ve officially been brainwashed by apple because now it feels so inconvenient to even carry a physical card in my pocket",
         "-1"
        ],
        [
         "4",
         "apple pay is so convenient secure and easy to use i used it while at the korean and japanese airports no need for physical credit cards",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets not forget that apple pay in 2014 require...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here in nz 50 of retailers don’t even have con...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i will forever acknowledge this channel with t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whenever i go to a place that doesn’t take app...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple pay is so convenient secure and easy to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Sentiment\n",
       "0  lets not forget that apple pay in 2014 require...          0\n",
       "1  here in nz 50 of retailers don’t even have con...         -1\n",
       "2  i will forever acknowledge this channel with t...          1\n",
       "3  whenever i go to a place that doesn’t take app...         -1\n",
       "4  apple pay is so convenient secure and easy to ...          1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].replace({'positive': 1, \n",
    "                         'negative': -1,\n",
    "                         'neutral': 0}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LowerCase all the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Comment'] = df['Comment'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df['Comment'] = df['Comment'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(lambda text: [re.sub(r'\\W', ' ', i) for i in text]) \n",
    "# keeps words, numbers and spaces, removes punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Removing basic english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Define negation words to retain (critical for sentiment analysis)\n",
    "negation_words = {\n",
    "    \"not\", \"no\", \"nor\", \"never\", \"none\", \"nobody\", \"nothing\", \"neither\",\n",
    "    \"nowhere\", \"don't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"hasn't\",\n",
    "    \"haven't\", \"hadn't\", \"won't\", \"wouldn't\", \"shan't\", \"shouldn't\", \"mightn't\",\n",
    "    \"mustn't\", \"needn't\", \"couldn't\", \"n't\", \"against\"\n",
    "}\n",
    "\n",
    "# Load default English stopwords and remove negation words\n",
    "custom_stopwords = set(stopwords.words('english')) - negation_words\n",
    "\n",
    "# Remove additional non-critical words (optional)\n",
    "non_critical_words = {\"'s\", \"'m\", \"'re\", \"'d\"}  # Remove possessives/contractions\n",
    "custom_stopwords = custom_stopwords - non_critical_words\n",
    "\n",
    "# Apply custom stopwords to the DataFrame\n",
    "df['Comment'] = df['Comment'].apply(\n",
    "    lambda tokens: [word for word in tokens if word not in custom_stopwords]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TIME!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the comments feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Features:\n",
      "   000  000 intro  0000  0018  0018 joonie   10  10 years  100  1000  10000  \\\n",
      "0  0.0        0.0   0.0   0.0          0.0  0.0       0.0  0.0   0.0    0.0   \n",
      "1  0.0        0.0   0.0   0.0          0.0  0.0       0.0  0.0   0.0    0.0   \n",
      "2  0.0        0.0   0.0   0.0          0.0  0.0       0.0  0.0   0.0    0.0   \n",
      "3  0.0        0.0   0.0   0.0          0.0  0.0       0.0  0.0   0.0    0.0   \n",
      "4  0.0        0.0   0.0   0.0          0.0  0.0       0.0  0.0   0.0    0.0   \n",
      "\n",
      "   ...  zoom  çok   đi   để   ơn   за  очень  спасибо  タッピング   너무  \n",
      "0  ...   0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0  0.0  \n",
      "1  ...   0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0  0.0  \n",
      "2  ...   0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0  0.0  \n",
      "3  ...   0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0  0.0  \n",
      "4  ...   0.0  0.0  0.0  0.0  0.0  0.0    0.0      0.0    0.0  0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))  # Unigrams + bigrams\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(lambda tokens: ' '.join(tokens)) # convert list of tokens to string\n",
    "X = vectorizer.fit_transform(df['Comment'])\n",
    "\n",
    "X = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"TF-IDF Features:\")\n",
    "print(X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"  # Use \"distilbert-base-uncased\" for DistilBERT\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=3)  # 3 classes: -1, 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(texts):\n",
    "    return tokenizer(\n",
    "        texts, padding=True, truncation=True, max_length=128, return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "# Tokenize the comments\n",
    "train_encodings = tokenize_function(df['Comment'].tolist())\n",
    "train_labels = tf.constant(df['Sentiment'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),  # Input features\n",
    "    train_labels            # Labels\n",
    ")).shuffle(1000).batch(16)  # Batch size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\mayan\\AppData\\Local\\Temp\\ipykernel_8420\\3659685789.py\", line 2, in <module>\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1229, in fit\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1804, in fit\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1398, in train_function\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1381, in step_function\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1370, in run_step\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1706, in train_step\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py\", line 143, in __call__\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py\", line 270, in call\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py\", line 5777, in sparse_categorical_crossentropy\n\nReceived a label value of -1 which is outside the valid range of [0, 3).  Label values: -1 1 0 -1 1 -1 1 -1 0 1 1 0 1 0 -1 -1\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_34488]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Batch size\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:1229\u001b[0m, in \u001b[0;36mTFPreTrainedModel.fit\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(keras\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mfit)\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1228\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m convert_batch_encoding(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\mayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\mayan\\AppData\\Local\\Temp\\ipykernel_8420\\3659685789.py\", line 2, in <module>\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1229, in fit\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1804, in fit\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1398, in train_function\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1381, in step_function\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\training.py\", line 1370, in run_step\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1706, in train_step\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py\", line 143, in __call__\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py\", line 270, in call\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"c:\\Users\\mayan\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py\", line 5777, in sparse_categorical_crossentropy\n\nReceived a label value of -1 which is outside the valid range of [0, 3).  Label values: -1 1 0 -1 1 -1 1 -1 0 1 1 0 1 0 -1 -1\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_34488]"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,  # Number of epochs\n",
    "    batch_size=16,  # Batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize test data\n",
    "test_encodings = tokenize_function(test_df['Comment'].tolist())\n",
    "test_labels = tf.constant(test_df['Sentiment'].tolist())\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),  # Input features\n",
    "    test_labels            # Labels\n",
    ")).batch(16)  # Batch size = 16\n",
    "\n",
    "# Evaluate\n",
    "results = model.evaluate(test_dataset)\n",
    "print(\"Test Accuracy:\", results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy\n",
    "\n",
    "1. RF w/o class weights- 73.11%\n",
    "2. RF w class weights - 73.56%\n",
    "3. XGBoost - 74.20%\n",
    "4. SVM(Linear) - 75.1%\n",
    "5. SVM (Poly) - 64.3%\n",
    "6. SVM (rbf) - 64.3%\n",
    "7. SVM (sigmoid) - 74.68%\n",
    "8. LGMBoost - 74%\n",
    "9. CatBoost - 72%\n",
    "9. Logistic Regression - 75%\n",
    "11. Naive Bayes - 69%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
